---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

# title: "Real Exchange Rate Behaviour: A Replication and Robustness Check
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: TRUE
Entry1: "Real Exchange Rate Behaviour: A Replication and Robustness Check"
Entry2: "Cassandra Pengelly | 20346212" # textbf for bold
Entry3: "Econometrics 871: Time Series Project"
Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
Logo_width: 0.5
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
# AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
# Author1: "Nico Katzke^[__Contributions:__  \\newline _The authors would like to thank no institution for money donated to this project. Thank you sincerely._]"  # First Author - note the thanks message displayed as an italic footnote of first page.
# Ref1: "Prescient Securities, Cape Town, South Africa" # First Author's Affiliation
# Email1: "nfkatzke\\@gmail.com" # First Author's Email address
# 
# Author2: "John Smith"
# Ref2: "Some other Institution, Cape Town, South Africa"
# Email2: "John\\@gmail.com"
# CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.
# 
# Author3: "John Doe"
# Email3: "Joe\\@gmail.com"
# 
# CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE
# 
# # Comment out below to remove both. JEL Codes only given if keywords also given.
# keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
# JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: TRUE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
# abstract: |
#   Abstract
---

<!-- First: Set default preferences for chunk options: -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!
# Loading packages used
if(!require("tidyverse")) install.packages("tidyverse")
if(!require("plm")) install.packages("plm")
library(bootUR)
library(tidyverse)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))

ind <- read_table("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Metrics/Time Series Project/R stuffs/Write_Up/data/files/ind.dat")
lnk <- read_table("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Metrics/Time Series Project/R stuffs/Write_Up/data/files/lnk.dat")
mal <- read_table("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Metrics/Time Series Project/R stuffs/Write_Up/data/files/mal.dat")
mnr <- read_table("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Metrics/Time Series Project/R stuffs/Write_Up/data/files/mnr.dat")
pak <- read_table("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Metrics/Time Series Project/R stuffs/Write_Up/data/files/pak.dat")
phl <- read_table("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Metrics/Time Series Project/R stuffs/Write_Up/data/files/phl.dat")
thi <- read_table("C:/Users/Cassandra/OneDrive/Documents/2021 Academics/Metrics/Time Series Project/R stuffs/Write_Up/data/files/thi.dat")

# adding in a column to each data set for the real exchange rate

rexIND <- ind %>% mutate(ENTRY = as.factor(ENTRY)) %>% mutate(rexIND = real_exchange(INDEX, INDCPI, USCPI)) %>% select(ENTRY, rexIND)
rexLNK <- lnk %>% mutate(ENTRY = as.factor(ENTRY)) %>% mutate(rexLNK = real_exchange(LNKEX, LNKCPI, USCPI)) %>% select(rexLNK)
rexMAL <- mal %>% mutate(ENTRY = as.factor(ENTRY)) %>% mutate(rexMAL = real_exchange(MALEX, MALCPI, USCPI)) %>% select(rexMAL)
rexMNR <- mnr %>% mutate(ENTRY = as.factor(ENTRY)) %>% mutate(MNREX = replace(MNREX, 203, 16.5)) %>% mutate(rexMNR = real_exchange(MNREX, MNRCPI, USCPI)) %>% select(rexMNR) #replaced the value for the exchange rate for 1974:11 with 16.5 (was 1.45)
rexPAK <- pak %>% mutate(ENTRY = as.factor(ENTRY)) %>% mutate(rexPAK = real_exchange(PAKEX, PAKCPI, USCPI)) %>% select(rexPAK)
rexPHL <- phl %>% mutate(ENTRY = as.factor(ENTRY)) %>% mutate(PHLEX = replace(PHLEX, 213, 7.7)) %>% mutate(rexPHL = real_exchange(PHLEX, PHLCPI, USCPI)) %>% select(rexPHL) #replaced the value for the exchange rate for 1975:09 with 7.7 (was 0.7)
rexTHI <- thi %>% mutate(ENTRY = as.factor(ENTRY)) %>% mutate(rexTHI = real_exchange(THIEX, THICPI, USCPI)) %>% select(rexTHI)

# binding the columns together for a panel data set of real exchange rates

pdata <- bind_cols(rexIND,rexLNK, rexMAL, rexMNR,  rexPAK,  rexPHL,  rexTHI)
```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->
\newpage

# Introduction \label{Introduction}

How do we compare living standards and economic productivity between countries? This is one of the questions that macroeconomics attempts to answer, and a number of tools have been developed within the field to this end. One of these tools is the Purchasing Power Parity (PPP) theory, which uses a basket of goods to compare the currencies of different countries. This theory has been widely tested using data, and the results have been divisive and somewhat puzzling (@puz). In this essay, I replicate^[More accurately, try my best to replicate] the paper "Real Exchange Rate Behaviour: Evidence from Black Markets" by @Kul, which tests the PPP hypothesis. @Kul finds that the behaviour of the real exchange rate is mean-reverting in the long-run, which suggests that the PPP theory is empirically supported. I include some other tests in addition to those presented in the paper as a robustness check on these results. 

This essay^[This essay was written in R using the package by @Texevier] is organised as follows. Section \ref{Context} contextualises Luintel's paper and discusses the robustness checks. Section \ref{Data} discusses the data and reports the results of the Wald-Wolfowitz tests. Section \ref{Unit} deals with the unit root tests and section \ref{Var} reports the results of the variance ratio test. The code for this replication can be found on Github [here](https://github.com/cass-code/metrics.git).


# Context and Evaluation \label{Context}

@Kul investigates whether the PPP hypothesis holds empirically. To test this theory, @Kul uses monthly black market real exchange rates (in terms of the US dollar) from eight developing Asian countries: India, Sri Lanka, Myanmar, Malaysia, Pakistan, Philippines, Taiwan and Thailand. Using data from developing countries (rather than from developed countries) was a novel approach for its time. The black market rates are used as a proxy for the float rates of developing countries. 

Practically, the paper has two main aims: the first is to determine whether there are segmented trends in the data, and the second is to test whether the panel data is stationary. At the time that this paper was written (early 2000s), the puzzle of PPP was that tests for unit roots failed to reject the null hypothesis. The null hypothesis in these cases was the presence of unit roots; these tests implied non-stationarity and discredited PPP, despite the support from economic theory(@puz). 

@Kul makes use of (more) powerful unit root tests for heterogeneous panels, and finds that real exchange rates are mean-reverting. This was novel for the time as most time-series studies rejected PPP and concluded that the real exchange rate followed a random walk. This suggested that any shocks to the real exchange rate were persistent and there was no mean-reversion either in the short or long term (@rog). @Kul finds that the black market real exchange rates do not behave in an excessively volatile manner, which conflicted with the findings of the literature at that time. Additionally, the findings of the study implied that such empirical investigations may not necessarily suffer from survivorship bias.

A critical part of Luintel's paper is testing for unit roots in the panel data; specifically, the paper makes use of the Im-Pesaran-Shin (IPS) T-bar test. In addition to replicating this test, I implement several other unit root tests as a robustness check and find that the results are mixed. @Kul [p.170] defends the choice of the IPS tests well, citing that they allow for the dynamics and error variances across groups and these tests may have better small sample properties. I run the IPS tests using @Kul's specified lags, and the AIC method. I then implement the panel stationarity tests proposed by @lev, @wu, @had, as well as a bootstrapped panel unit root test from @pal.. 

# Data \label{Data}

The data used for the analysis is a series on black market nominal exchange rates and consumer price indices (CPI) for 8 developing Asian countries, namely: India, Sri Lanka, Myanmar, Malaysia, Pakistan, Philippines, Taiwan and Thailand. I take a subset of these countries by excluding Taiwan^[I excluded Taiwan because there is some data missing from the set and I don't know how to manage an unbalanced panel. However, it is also interesting to test if the results of the paper hold when taking a subset of the data.] from the analysis. @Kul sources data from various issues of *Pick's Currency Year Book* and *World Currency Year Book*. The data used for Luintel's paper is accessible through the Journal of Applied Econometrics archive, which is where I attained my data. The sample period runs for 31 periods from January 1958 to June 1989. This sample period is split into two parts: Bretton Woods and after Bretton Woods (also referred to as pre-float period and the float period).

The nominal exchange rates are units currencies per unit of US dollar. There were two mistakes in the nominal exchange rate datasets: for Myanmar November 1974, there was a value of 1.45, which I replaced with 16.5 (based on interpolation). And for the Philippines in September 1975,  there was a value of 0.7 with which I replaced with 7.7 (based on interpolation).^[I discovered these mistakes when there was a dramatic difference in my plots of the real exchange rates and Luintel's plots.] Luintel sources the CPI figures from various issues of International Financial Statistics (which are included in Luintel's dataset available in the JAE data archives).  

To calculate the real exchange rates, I follow the lead of @Kul [p. 165] and apply the following formula to the nominal exchange rates:

$$
rex = log(Nominal Exchange Rate) - log(CPI) + log(United States CPI)
$$

I plot the real exchange rate series below in \ref{Figure1}. The plots below match those of @Kul [p. 166] and preliminarily indicate that the real exchange rates are trending. Additionally, the graphs show that the black market exchange rates are somewhat volatile. As expected, we see that after the first oil shock of 1973 the currencies appreciated and then slowly reverted. The plots suggest that the trends are segmented. @Kul [p. 169] tests this hypothesis using formal tests, and I follow suit - the results of the Wald-Wolfowitz Tests are reported below after the plots, in table \ref{wald}.

```{r Figure1, echo = FALSE, include= TRUE, warning =  FALSE, fig.height= 9, fig.align = 'center', fig.ext = 'png'}

library(tidyverse)
g <- rex_plots_combined(pdata)

```

```{r Figure2, echo = FALSE, include= TRUE, warning =  FALSE, fig.height= 9, fig.align = 'center', fig.cap = "Plot of Real Exchange Rates over Time\\label{Figure1}", fig.ext = 'png'}

library(tidyverse)
h <- rex_plots_combined1(pdata)

# had an issue with some extra grob table information printing - resolved this by including grid.draw in the plot function and not including "h" here in the chunk
```

## Wald-Wolfowitz Tests \label{wald}

The Wald-Wolfowitz test is a nonparametric test that discriminates between the underlying distributions of the Bretton Woods and post Bretton Woods real exchange rates. Essentially, it tests whether two random samples are from populations with the same distribution (this is the null hypothesis), or whether the two samples descend from populations with different distributions (the alternative hypothesis).^[@Kul [p. 169] gives the mathematical details of the test.] 

The critical values for this test at 1% and 5% are 2.58 and 1.96 respectively. \ref{Wtable} shows that the tests reject the null hypothesis at a 1% significance level for all the countries. These results imply that the Bretton Woods real exchange rates descend from a population that follows a distribution that may differ in skewness, kurtosis and dispersion from that of the post Bretton Woods. This suggests that it is important to include the Bretton Woods period in our analysis of real exchange rates. @Kul [p. 169] reports smaller test statistics, but rejects the null comfortably for all of the countries.

```{r Figure3, echo = FALSE, include= TRUE, warning =  FALSE, fig.height= 5, fig.align = 'center', fig.ext = 'png', results='asis'}

# The Wald-Wolfowitz tests

library(xtable)
data <- wald(pdata) %>% tibble::as_tibble()

table <- xtable(data, caption = "Wald-Wolfowitz tests", label = "Wtable")
  print.xtable(table,
             # tabular.environment = "longtable",
             floating = TRUE,
             table.placement = 'H',
             include.rownames = FALSE,
             # scalebox = 0.3,
             comment = FALSE,
             caption.placement = 'top'
             )

```

# Unit Root Tests \label{Unit}

We can define relative PPP as:
$$
\Delta s_{t}=\Delta p_{t}-\Delta p_{t}^{*} \label{eq1}
$$
This relationship shows that the percentage change in the nominal exchange rate should be equal to the difference in inflation between the domestic and foreign country. The real exchange rate $\left(q_{t}\right)$ is given by:
$$
q_{t}=s_{t}-p_{t}+p_{t}^{*} \label{eq2}
$$
From \ref{eq1} we can see that the real exchange rate should be zero or a constant if PPP holds continuously. To test whether PPP holds, we can test whether the real exchange rate is stationary. @Kul argues that the power of unit-root tests is significantly higher when using a panel data set as opposed to a univariate time series. The first panel unit-root test that @Kul runs is the Augmented Dickey-Fuller test, which fails to reject the null hypothesis (there exists a unit root, and therefore the process is nonstationary) for all the countries. The only exception is for Pakistan in the post Bretton Woods period. My replicated tests show similar results in \ref{ADF}, with most countries failing to reject the null (with the exceptions occurring at a 5% level for four countries post Bretton Woods^[India, Malaysia, Pakistan and Thailand]). Both @Kul and my tests include a time trend, but the non-stationary results hold when excluding this trend. 

However, the Dickey-Fuller tests are known for their low power. Low statistical power means we have a higher probability of committing a type 2 error: failing to reject the null hypothesis when the alternative hypothesis is true. In our context, this means we may be incorrectly concluding that real exchange rates are nonstationary. Thus, we need to consider other tests when testing for stationarity, which are discussed below.


```{r ADF, echo = FALSE, include= TRUE, warning =  FALSE, results='asis'}
library(tidyverse)
library(xtable)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))

bret <- pdata %>% slice_head(n =183) #prefloat era bretton woods
postbret <- pdata %>% slice_tail(n = 195) # float era post bretton woods
B1 <- (ADF1(bret)) %>% select(-Countries) %>% rename("Bretton Woods (1958:1-1973:3)" = "Dickey-Fuller")
B2<- (ADF2(postbret)) %>% select(-Countries) %>% rename("Post-Bretton Woods (1973:4-1989:6)" = "Dickey-Fuller")
A <- ADF(pdata) %>% rename("Full Sample" = "Dickey-Fuller")

fullADF <- bind_cols(A, B1, B2)
data = fullADF %>% tibble::as_tibble()
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- c(0)
  addtorow$command  <- c(paste("\\hline \n",
                               "\\endhead \n",
                               "\\hline \n",
                               "{\\footnotesize Continued on next page} \n",
                               "\\endfoot \n",
                               "\\endlastfoot \n",sep=""))
table <- xtable(data, caption = "Augmented Dickey-Fuller Tests", label = "ADF")
  print.xtable(table,
             tabular.environment = "longtable",
             floating = FALSE, # Leave this as is.
             table.placement = 'H', # Leave this as is.
             booktabs = T, # Aesthetics
             include.rownames = FALSE,  # Typically you don't want this in a table.
             add.to.row = addtorow, # For adding the Continued on next page part...
             comment = FALSE,
             caption.placement = 'top',  # Where do you want the caption?
             size="\\fontsize{10pt}{11pt}\\selectfont"  # Size of text in table..
             )
```
As noted by @pes [p.18], when using country data for macroeconomic applications, there are often contemporaneous correlations within the time series, which is a relevant concern for testing the PPP hypothesis. There may be unobserved common factors or spatial spillover effects, which need to be accounted for in the unit root test. Modelling cross section dependence in panel data sets is still an emerging field, but @im suggest that the appropriate test statistic is the T-bar test based on cross-sectional demeaned regressions. This is the approach that I take below (Im-Pesaran-Shin T-bar test). I use the same lags as @Kul for the first IPS T-bar test. For the full sample: Malaysia(l) and Thailand(1), for the Bretton Woods period: Thailand(1), and for the post Bretton Woods period: Malaysia(l) and Thailand(1). The IPS test is run on the cross-sectionally demeaned data.

The results (\ref{ips}) of the first IPS tests show that the null hypothesis is rejected at a 1% level of significance for the full sample. This supports a stationary real exchange rate and therefore is evidence towards the PPP. @Kul [p.173] finds similar results. However, for the Bretton Woods and Post Bretton Woods, my test fails to reject the null hypothesis, whereas @Kul rejects the null at 1%. This difference could be due to a difference in how the data was demeaned or because I am testing a subset of currencies.

```{r IPS, echo = FALSE, include= TRUE, warning =  FALSE, results='asis'}
#pg173
pdata2 <- pdata %>% select(-ENTRY)
dm <- pdata2 %>% mutate(mean = rowMeans(pdata2)) %>% mutate(rexIND = rexIND - mean, rexLNK = rexLNK - mean, rexMAL = rexMAL - mean, rexMNR = rexMNR - mean, rexPAK = rexPAK - mean, rexPHL = rexPHL - mean, rexTHI = rexTHI - mean) %>% select(-mean) #demeaned data
 
dmbret <- pdata2 %>% mutate(mean = rowMeans(pdata2)) %>% mutate(rexIND = rexIND - mean, rexLNK = rexLNK - mean, rexMAL = rexMAL - mean, rexMNR = rexMNR - mean, rexPAK = rexPAK - mean, rexPHL = rexPHL - mean, rexTHI = rexTHI - mean) %>% select(-mean) %>% slice_head(n =183) #prefloat era bretton woods demeaned data

dmpostbret<- pdata2 %>% mutate(mean = rowMeans(pdata2)) %>% mutate(rexIND = rexIND - mean, rexLNK = rexLNK - mean, rexMAL = rexMAL - mean, rexMNR = rexMNR - mean, rexPAK = rexPAK - mean, rexPHL = rexPHL - mean, rexTHI = rexTHI - mean) %>% select(-mean) %>% slice_tail(n = 195) #post bretton woods demeaned data

library(xtable)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
 # full <- ips(dm)
 # bre <- ips(dmbret)
 # post <- ips(dmpostbret)
 time <- data.frame(Period = c("Full Sample", "", "Bretton Woods","", "Post Bretton Woods", ""))
 # data1 <- bind_rows(full, bre, post)
 try <- ipsall(dm, dmbret, dmpostbret)
 # data2 <- bind_cols(time, data1)
 data2 <- bind_cols(time, try)
data = data2 %>% tibble::as_tibble()
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- c(0)
  addtorow$command  <- c(paste("\\hline \n",
                               "\\endhead \n",
                               "\\hline \n",
                               "{\\footnotesize Continued on next page} \n",
                               "\\endfoot \n",
                               "\\endlastfoot \n",sep=""))
table <- xtable(data, caption = "IPS Panel Unit Root Tests (Tbar)", label = "ips")
  print.xtable(table,
             tabular.environment = "longtable",
             floating = FALSE, # Leave this as is.
             table.placement = 'H', # Leave this as is.
             booktabs = T, # Aesthetics
             include.rownames = FALSE,  # Typically you don't want this in a table.
             add.to.row = addtorow, # For adding the Continued on next page part...
             comment = FALSE,
             caption.placement = 'top',  # Where do you want the caption?
             size="\\fontsize{12pt}{13pt}\\selectfont"  # Size of text in table..
             )

```

Next, I rerun the IPS test and use Akaike's information criterion (AIC) to select the lags as a robustness check on the first IPS test. The results (\ref{ipsAIC}) show that the null hypothesis is rejected at 1% for the full sample and for the post Bretton Woods period. This implies there is no unit root present, and real exchange rates are mean-reverting in the long run. This supports the findings of @Kul. However, the test again fails to reject the null for the Bretton Woods period, which is contrary to @Kul's results. 

```{r, echo = FALSE, include= TRUE, warning =  FALSE, results='asis'}
#pg173
pdata2 <- pdata %>% select(-ENTRY)
dm <- pdata2 %>% mutate(mean = rowMeans(pdata2)) %>% mutate(rexIND = rexIND - mean, rexLNK = rexLNK - mean, rexMAL = rexMAL - mean, rexMNR = rexMNR - mean, rexPAK = rexPAK - mean, rexPHL = rexPHL - mean, rexTHI = rexTHI - mean) %>% select(-mean) #demeaned data
 
dmbret <- pdata2 %>% mutate(mean = rowMeans(pdata2)) %>% mutate(rexIND = rexIND - mean, rexLNK = rexLNK - mean, rexMAL = rexMAL - mean, rexMNR = rexMNR - mean, rexPAK = rexPAK - mean, rexPHL = rexPHL - mean, rexTHI = rexTHI - mean) %>% select(-mean) %>% slice_head(n =183) #prefloat era bretton woods demeaned data

dmpostbret<- pdata2 %>% mutate(mean = rowMeans(pdata2)) %>% mutate(rexIND = rexIND - mean, rexLNK = rexLNK - mean, rexMAL = rexMAL - mean, rexMNR = rexMNR - mean, rexPAK = rexPAK - mean, rexPHL = rexPHL - mean, rexTHI = rexTHI - mean) %>% select(-mean) %>% slice_tail(n = 195) #post bretton woods demeaned data

library(xtable)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
 full <- ips_AIC(dm)
 bre <- ips_AIC(dmbret)
 post <- ips_AIC(dmpostbret)
 time <- data.frame(Period = c("Full Sample", "", "Bretton Woods","", "Post Bretton Woods", ""))
 data1 <- bind_rows(full, bre, post)
 data2 <- bind_cols(time, data1)
data = data2 %>% tibble::as_tibble()
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- c(0)
  addtorow$command  <- c(paste("\\hline \n",
                               "\\endhead \n",
                               "\\hline \n",
                               "{\\footnotesize Continued on next page} \n",
                               "\\endfoot \n",
                               "\\endlastfoot \n",sep=""))
table <- xtable(data, caption = "IPS Panel Unit Root Tests (Tbar)", label = "ipsAIC")
  print.xtable(table,
             tabular.environment = "longtable",
             floating = FALSE, # Leave this as is.
             table.placement = 'H', # Leave this as is.
             booktabs = T, # Aesthetics
             include.rownames = FALSE,  # Typically you don't want this in a table.
             add.to.row = addtorow, # For adding the Continued on next page part...
             comment = FALSE,
             caption.placement = 'top',  # Where do you want the caption?
             size="\\fontsize{12pt}{13pt}\\selectfont"  # Size of text in table..
             )

```

As a further robustness check on the results of @Kul, I test the panel for unit roots using the tests proposed by @lev (LL), @wu (MadWu), @had (Hadri). I used the package by @plm to run these tests. For the @lev and @wu tests I again used AIC for the lag selection. The @had test directly tests for stationarity and has as the null hypothesis that all the panels are (trend) stationary. 

The results presented in \ref{uunit} show that all @lev tests fail to reject the null hypothesis (i.e. there are unit roots present). The only @wu test that rejects the null hypothesis is the one for post Bretton Woods when a trend is included. Otherwise this test suggests that the real exchange rate is nonstationary. All @had tests reject the null hypothesis at a 1% level of significance. A rejection of the null here is an indication of nonstationarity. These results can be interpereted in two ways. They can suggest that real exchange rates are nonstationary, the PPP doesn't hold empirically and @Kul's results are not robust. Or these results support @Kul's claim that the IPS test is the correct test to use because other unit root tests are too weak to correctly identify stationary processes.

```{r units, echo = FALSE, include= TRUE, warning =  FALSE, results='asis'}
pdata2 <- pdata %>% select(-ENTRY)
bret <- pdata2 %>% slice_head(n =183) #prefloat era bretton woods
postbret <- pdata2 %>% slice_tail(n = 195) # float era post bretton woods

library(xtable)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
 full <- unit(pdata2)
 bre <- unit(bret)
 post <- unit(postbret)
 time <- data.frame(Period = c("Full Sample", "", "","","","", "Bretton Woods","","","","","", "Post Bretton Woods", "","","","",""))
 data1 <- bind_rows(full, bre, post)
 data2 <- bind_cols(time, data1)
data = data2 %>% tibble::as_tibble()
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- c(0)
  addtorow$command  <- c(paste("\\hline \n",
                               "\\endhead \n",
                               "\\hline \n",
                               "{\\footnotesize Continued on next page} \n",
                               "\\endfoot \n",
                               "\\endlastfoot \n",sep=""))
table <- xtable(data, caption = "Various Panel Unit Root Tests", label = "uunit")
  print.xtable(table,
             tabular.environment = "longtable",
             floating = FALSE, # Leave this as is.
             table.placement = 'H', # Leave this as is.
             booktabs = T, # Aesthetics
             include.rownames = FALSE,  # Typically you don't want this in a table.
             add.to.row = addtorow, # For adding the Continued on next page part...
             comment = FALSE,
             caption.placement = 'top',  # Where do you want the caption?
             size="\\fontsize{12pt}{13pt}\\selectfont"  # Size of text in table..
             )

```

As a final check on the stationarity of real exchange rates, I employ a panel bootstrap group-mean union test as proposed by @pal. The test has a null hypothesis that all series have a unit root. If the null is rejected then some proportion of the series is stationary. I also ran the test on the cross-section demeaned data (in addition to the non-demeaned data) for the full sample. The results are shown in \ref{Boot}. The test fails to reject the null for both series, which suggests the panel is non-stationary. This undermines the results of @Kul. However, the number of runs for the test was 1000^[My laptop struggled with runs higher than this unfortunately.], which is quite low for bootstrapping and the test may be giving inaccurate results.

```{r Boot, echo = FALSE, include= TRUE, warning =  FALSE, results='asis'}
pdata2 <- pdata %>% select(-ENTRY)
dm <- pdata2 %>% mutate(mean = rowMeans(pdata2)) %>% mutate(rexIND = rexIND - mean, rexLNK = rexLNK - mean, rexMAL = rexMAL - mean, rexMNR = rexMNR - mean, rexPAK = rexPAK - mean, rexPHL = rexPHL - mean, rexTHI = rexTHI - mean) %>% select(-mean)

library(xtable)
load("palm1.Rda")
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
 #palm <- panel(pdata2, dm)
 table <- xtable(palm1, caption = "Bootstrapped panel unit root tests", label = "Boot")
  print.xtable(table,
             # tabular.environment = "longtable",
             floating = TRUE,
             table.placement = 'H',
             include.rownames = FALSE,
             # scalebox = 0.3,
             comment = FALSE,
             caption.placement = 'top'
             )

```


# Variance Ratio Test \label{Var}

@Kul [p. 174] makes use of the variance ratio test to examine the persistence in real exchange rates. The variance ratio $V^k$ is defined as: 

$$
V^k = \frac{Var(y_t - y_{t-k})}{k \times Var(y_t - y_{t-1}) } 
$$

where k is the lag length, $Var(y_t - y_{t-k})$ and $Var(y_t - y_{t-1})$ are the variances of kth difference and the first difference of a time series $y_t$. @Kul [p.174] goes into detail of the intuition and the interpretation of this test. I replicate this test, and table (\ref{v}) shows results for the full sample for up to 20 months. The results of the variance ratio test for the Bretton Woods period and post Bretton Woods period (for up to 20 months^[The results for 190 months are available upon request; it has been omitted to save space]) can be found in the Appendix (\ref{A}). I find the same variance ratios as @Kul for all the countries. My standard errors (se) were slightly larger because the formula I used for the variance was different^[I tried to replicate the variance formula as it is in the paper but it kept breaking the code of the function I built, unfortunately] but the qualitative results remain similar. For all the countries except Myanmar, the variance ratios are all significantly different from zero for k ranging from 1 - 70, and the cut-off lag length is 70 for all the countries. According to @Kul, this suggests that the real exchange rates (for the countries other than Myanmar) are stationary. The two sub-periods show similar results (\ref{A}).

```{r Vtab, results = 'asis'}

library(xtable)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
 VR <-cvar_table(pdata)
 VRtab <- vtab(VR) %>% slice_head(n=40)
data = VRtab %>% tibble::as_tibble()
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- c(0)
  addtorow$command  <- c(paste("\\hline \n",
                               "\\endhead \n",
                               "\\hline \n",
                               "{\\footnotesize Continued on next page} \n",
                               "\\endfoot \n",
                               "\\endlastfoot \n",sep=""))
table <- xtable(data, caption = "Variance Ratio Test for Full Sample Up to month 20", label = "v")
  print.xtable(table,
             tabular.environment = "longtable",
             floating = FALSE, # Leave this as is.
             table.placement = 'H', # Leave this as is.
             booktabs = T, # Aesthetics
             include.rownames = FALSE,  # Typically you don't want this in a table.
             add.to.row = addtorow, # For adding the Continued on next page part...
             comment = FALSE,
             caption.placement = 'top',  # Where do you want the caption?
             size="\\fontsize{12pt}{13pt}\\selectfont"  # Size of text in table..
             )
```


# Conclusion

@Kul performs a number of tests to show that real exchange rates are stationary and thus PPP holds empirically. My replication of the IPS test and variance ratio test support the results of the paper. However, the robustness checks of using other panel unit root tests show that real exchange rates are nonstationary. This undermines the results and conclusions reached by @Kul. An interesting study would be to extend the panel (in terms of the time dimension and include more countries) and apply unit root testing to ascertain whether real exchange rates are stationary.

\newpage

# References {-}

<div id="refs"></div>

\newpage

# Appendix \label{A} {-}

```{r Vtab2, results = 'asis'}

library(xtable)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
 VR <-cvar_table(bret)
 VRtab <- vtab(VR)  %>% slice_head(n=40)
data = VRtab %>% tibble::as_tibble()
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- c(0)
  addtorow$command  <- c(paste("\\hline \n",
                               "\\endhead \n",
                               "\\hline \n",
                               "{\\footnotesize Continued on next page} \n",
                               "\\endfoot \n",
                               "\\endlastfoot \n",sep=""))
table <- xtable(data, caption = "Variance Ratio Test for Bretton Woods period up to month 20")
  print.xtable(table,
             tabular.environment = "longtable",
             floating = FALSE, # Leave this as is.
             table.placement = 'H', # Leave this as is.
             booktabs = T, # Aesthetics
             include.rownames = FALSE,  # Typically you don't want this in a table.
             add.to.row = addtorow, # For adding the Continued on next page part...
             comment = FALSE,
             caption.placement = 'top',  # Where do you want the caption?
             size="\\fontsize{12pt}{13pt}\\selectfont"  # Size of text in table..
             )
```

```{r Vtab3, results = 'asis'}

library(xtable)
list.files('code/', full.names = T, recursive = T) %>% as.list() %>% walk(~source(.))
 VR <-cvar_table(postbret)
 VRtab <- vtab(VR)  %>% slice_head(n=40)
data = VRtab %>% tibble::as_tibble()
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- c(0)
  addtorow$command  <- c(paste("\\hline \n",
                               "\\endhead \n",
                               "\\hline \n",
                               "{\\footnotesize Continued on next page} \n",
                               "\\endfoot \n",
                               "\\endlastfoot \n",sep=""))
table <- xtable(data, caption = "Variance Ratio Test for post Bretton Woods period up to 20 months")
  print.xtable(table,
             tabular.environment = "longtable",
             floating = FALSE, # Leave this as is.
             table.placement = 'H', # Leave this as is.
             booktabs = T, # Aesthetics
             include.rownames = FALSE,  # Typically you don't want this in a table.
             add.to.row = addtorow, # For adding the Continued on next page part...
             comment = FALSE,
             caption.placement = 'top',  # Where do you want the caption?
             size="\\fontsize{12pt}{13pt}\\selectfont"  # Size of text in table..
             )
```



